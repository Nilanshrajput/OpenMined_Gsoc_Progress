{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "PysSyft-Bert.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilanshrajput/OpenMined_Gsoc_Progress/blob/master/PysSyft-Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX1c-q96IUZq",
        "colab_type": "code",
        "outputId": "3922210d-452c-4a68-afff-80479968dda2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install 'syft[udacity]'\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft[udacity]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8b/dc9a253392908d480322466832d618d85cdb1b66a1781604cf1064b50c32/syft-0.2.4-py3-none-any.whl (341kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 81kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 174kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 184kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 194kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 204kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 215kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 225kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 235kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 245kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 256kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 266kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 276kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 286kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 296kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 307kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 317kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 327kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 337kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 348kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib~=1.6.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.6.0)\n",
            "Collecting websockets~=8.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\r\u001b[K     |████▏                           | 10kB 23.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20kB 22.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 30kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 51kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 61kB 16.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 71kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.18.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.18.2)\n",
            "Collecting phe~=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/32/0e/568e97b014eb14e794a1258a341361e9da351dc6240c63b89e1541e3341c/phe-1.4.0.tar.gz\n",
            "Collecting Pillow~=6.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 10.2MB/s \n",
            "\u001b[?25hCollecting lz4~=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/81/011fef8766fb0ef681037ad6fee96168ee03a864464986cbaa23e5357704/lz4-3.0.2-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.1.2)\n",
            "Requirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.4.1)\n",
            "Collecting websocket-client~=0.57.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 50.9MB/s \n",
            "\u001b[?25hCollecting requests~=2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.0.0)\n",
            "Collecting syft-proto~=0.2.5.a1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/ab/849e6ef6c0e7af1a2a1d7a18f478fa07cd2217ed63867ab101ad5abff302/syft_proto-0.2.5a1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision~=0.5.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (0.5.0)\n",
            "Requirement already satisfied: tornado==4.5.3 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (4.5.3)\n",
            "Requirement already satisfied: torch~=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft[udacity]) (1.4.0)\n",
            "Collecting flask-socketio~=4.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/66/44/edc4715af85671b943c18ac8345d0207972284a0cd630126ff5251faa08b/Flask_SocketIO-4.2.1-py2.py3-none-any.whl\n",
            "Collecting tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/be/a4c0af9fdc5e5cee28495460538acf2766382bd572e01d4847abc7608dba/tf_encrypted-0.5.9-py3-none-manylinux1_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (7.1.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft[udacity]) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client~=0.57.0->syft[udacity]) (1.12.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft[udacity]) (2020.4.5.1)\n",
            "Collecting protobuf>=3.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/02/5432412c162989260fab61fa65e0a490c1872739eb91a659896e4d554b26/protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 50.2MB/s \n",
            "\u001b[?25hCollecting python-socketio>=4.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/cb/631c0b713daea3938e66d4c0923e88f3c0b57b026f860ea76e0337bc9c7a/python_socketio-4.5.1-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 49.5MB/s \n",
            "\u001b[?25hCollecting tensorflow<2,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask~=1.1.1->syft[udacity]) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.1->syft-proto~=0.2.5.a1->syft[udacity]) (46.1.3)\n",
            "Collecting python-engineio>=3.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/aa/c975982df73c4bcd087732db14b05306e8a3f3f24596cc18647746539290/python_engineio-3.12.1-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.28.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.0.8)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (3.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.6MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == \"udacity\"->syft[udacity]) (3.2.1)\n",
            "Building wheels for collected packages: phe, pyyaml, gast\n",
            "  Building wheel for phe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phe: filename=phe-1.4.0-py2.py3-none-any.whl size=37362 sha256=42d2726eba564ff8c82561135559174f636b2ad3440cb9202de0b1b1150bf468\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/dc/36/dcb6bf0f1b9907e7b710ace63e64d08e7022340909315fdea4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=7b32a5364cc56e685895d91f7a10dc62dee84f6f96dbe428c5f9b966801a96ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=04a3171a954124324120dcc9be92ae5f6b6df14d3e0337515d5e5bcb67a638a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built phe pyyaml gast\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: websockets, phe, Pillow, lz4, websocket-client, requests, protobuf, syft-proto, python-engineio, python-socketio, flask-socketio, pyyaml, gast, tensorboard, tensorflow-estimator, tensorflow, tf-encrypted, syft\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: protobuf 3.10.0\n",
            "    Uninstalling protobuf-3.10.0:\n",
            "      Successfully uninstalled protobuf-3.10.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed Pillow-6.2.2 flask-socketio-4.2.1 gast-0.2.2 lz4-3.0.2 phe-1.4.0 protobuf-3.11.3 python-engineio-3.12.1 python-socketio-4.5.1 pyyaml-5.3.1 requests-2.22.0 syft-0.2.4 syft-proto-0.2.5a1 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 tf-encrypted-0.5.9 websocket-client-0.57.0 websockets-8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 4.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 95kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.22.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=158d9ee942cca57179666d61a8fee4b73ce3814446042f698d831c527b07dd09\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcqIbOZ8Ivoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE7SLTRGL2KO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.mkdir(\"bert-base-uncased\")\n",
        "os.mkdir(\"data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AWfyU7-JRth",
        "colab_type": "code",
        "outputId": "ff266b6e-3c41-41ec-b8f5-cd31a44bd836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/19018/1053282/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1587571018&Signature=fwhs4MKzQldqTtkIVjlMdSwoT6yVTiYkE3EFSielSEnF46sJGKrKiwdLIYP%2F1axzJ5SDAgeY5rR8evqoWI0jRFO1i%2FdhTRrAq2lU0RYaz10p4HRN%2BgVfanD7RnBs0ck4hFBP9ySvwWTrmPn9wOkn%2FUt%2FjerP87cMa4j0YeT5iWjDNdZ03yUT0FfyHnhB3pGBy%2FFZEi4Q0Lv0LFU6biS%2FRp07tjZvAROl1POuZlYmLEq%2BUK7N8HUC21nlFCrLy2iAsKKbrPOUZBfJuh7ohIJrW2%2BONKtwwJ1hJc6frTqL6etqvyct0FBsgL3m9dm6pFTYQ7BGUDx42ZioQG2gj8ljPw%3D%3D&response-content-disposition=attachment%3B+filename%3Djigsaw-multilingual-toxic-comment-classification.zip\" -c -O 'jigsaw-multilingual-toxic-comment-classification.zip'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-21 12:35:13--  https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/19018/1053282/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1587571018&Signature=fwhs4MKzQldqTtkIVjlMdSwoT6yVTiYkE3EFSielSEnF46sJGKrKiwdLIYP%2F1axzJ5SDAgeY5rR8evqoWI0jRFO1i%2FdhTRrAq2lU0RYaz10p4HRN%2BgVfanD7RnBs0ck4hFBP9ySvwWTrmPn9wOkn%2FUt%2FjerP87cMa4j0YeT5iWjDNdZ03yUT0FfyHnhB3pGBy%2FFZEi4Q0Lv0LFU6biS%2FRp07tjZvAROl1POuZlYmLEq%2BUK7N8HUC21nlFCrLy2iAsKKbrPOUZBfJuh7ohIJrW2%2BONKtwwJ1hJc6frTqL6etqvyct0FBsgL3m9dm6pFTYQ7BGUDx42ZioQG2gj8ljPw%3D%3D&response-content-disposition=attachment%3B+filename%3Djigsaw-multilingual-toxic-comment-classification.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.28.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.28.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1158883783 (1.1G) [application/zip]\n",
            "Saving to: ‘jigsaw-multilingual-toxic-comment-classification.zip’\n",
            "\n",
            "jigsaw-multilingual 100%[===================>]   1.08G  74.6MB/s    in 13s     \n",
            "\n",
            "2020-04-21 12:35:26 (84.4 MB/s) - ‘jigsaw-multilingual-toxic-comment-classification.zip’ saved [1158883783/1158883783]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn8B2J5UKeo9",
        "colab_type": "code",
        "outputId": "57f111db-eeb9-48b0-9bea-baf63a61b988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "!unzip /content/jigsaw-multilingual-toxic-comment-classification.zip -d /content/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/jigsaw-multilingual-toxic-comment-classification.zip\n",
            "  inflating: /content/data/jigsaw-toxic-comment-train-processed-seqlen128.csv  \n",
            "  inflating: /content/data/jigsaw-toxic-comment-train.csv  \n",
            "  inflating: /content/data/jigsaw-unintended-bias-train-processed-seqlen128.csv  \n",
            "  inflating: /content/data/jigsaw-unintended-bias-train.csv  \n",
            "  inflating: /content/data/sample_submission.csv  \n",
            "  inflating: /content/data/test-processed-seqlen128.csv  \n",
            "  inflating: /content/data/test.csv  \n",
            "  inflating: /content/data/validation-processed-seqlen128.csv  \n",
            "  inflating: /content/data/validation.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6yBDOf5KxhR",
        "colab_type": "code",
        "outputId": "e671c46f-40ee-4e86-8f78-62c87f388946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-data-sets/431504/819665/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1587571188&Signature=mYI15idqV4d0omPx5rIicdhZOIJ%2BDqUzafPHGQ2uXfC4k0TrA73htXO7zEYBIrdj%2Fkhq65Hq%2Bk%2Fx4n%2FZfz2l%2Fa00xXG3r6aaQu2oDBZ4C51dfNK3ScPn2reVjeLFvkbHZY8dq8a4Ag4JODSY5CVKEqDRpsF65JhBRBGolDeIlc7nSTHy72uUqnrB%2BHWpHQjeIyDLMaIx5P8AXTBLQ3wJxKXKVvIDeX%2FtAfDlIXZVSt6lO8ipzBqnxnhZGzBu4ZGAw0agS04htarJSYGjwwYJ7mfHKSRCydEpFUrXZPsss3p3AW6nlG%2BFCyYUc4DXiD5RALFeKemGpMkNy3Ux9YG%2FSA%3D%3D&response-content-disposition=attachment%3B+filename%3Dbert-base-uncased.zip\" -c -O 'bert-base-uncased.zip'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-21 12:36:39--  https://storage.googleapis.com/kaggle-data-sets/431504/819665/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1587571188&Signature=mYI15idqV4d0omPx5rIicdhZOIJ%2BDqUzafPHGQ2uXfC4k0TrA73htXO7zEYBIrdj%2Fkhq65Hq%2Bk%2Fx4n%2FZfz2l%2Fa00xXG3r6aaQu2oDBZ4C51dfNK3ScPn2reVjeLFvkbHZY8dq8a4Ag4JODSY5CVKEqDRpsF65JhBRBGolDeIlc7nSTHy72uUqnrB%2BHWpHQjeIyDLMaIx5P8AXTBLQ3wJxKXKVvIDeX%2FtAfDlIXZVSt6lO8ipzBqnxnhZGzBu4ZGAw0agS04htarJSYGjwwYJ7mfHKSRCydEpFUrXZPsss3p3AW6nlG%2BFCyYUc4DXiD5RALFeKemGpMkNy3Ux9YG%2FSA%3D%3D&response-content-disposition=attachment%3B+filename%3Dbert-base-uncased.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.117.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.117.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407987655 (389M) [application/zip]\n",
            "Saving to: ‘bert-base-uncased.zip’\n",
            "\n",
            "bert-base-uncased.z 100%[===================>] 389.09M  72.8MB/s    in 5.3s    \n",
            "\n",
            "2020-04-21 12:36:45 (72.8 MB/s) - ‘bert-base-uncased.zip’ saved [407987655/407987655]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br6rLEAbKxYP",
        "colab_type": "code",
        "outputId": "3963fe1c-64a9-48d5-e176-4ad883cb7df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!unzip bert-base-uncased.zip -d /content/bert-base-uncased"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  bert-base-uncased.zip\n",
            "  inflating: /content/bert-base-uncased/config.json  \n",
            "  inflating: /content/bert-base-uncased/pytorch_model.bin  \n",
            "  inflating: /content/bert-base-uncased/vocab.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seOJIBZIUJz",
        "colab_type": "code",
        "outputId": "31c27bb1-e1f3-43a4-fce1-a4a242d6eb5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import syft as sy\n",
        "import torch\n",
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "# create a couple workers\n",
        "\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.2.so'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESA0AYOkIK1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from tqdm import tqdm\n",
        "\n",
        "import transformers\n",
        "from transformers import AdamW\n",
        "from transformers import BertModel, BertConfig\n",
        "\n",
        "\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VY0wK8wIK1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 10\n",
        "BERT_PATH = \"/content/bert-base-uncased\"\n",
        "MODEL_PATH = \"model.bin\"\n",
        "TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
        "    BERT_PATH,\n",
        "    do_lower_case=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtFUdME0IK11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTDataset:\n",
        "    def __init__(self, comment_text, target):\n",
        "        self.comment_text = comment_text\n",
        "        self.target = target\n",
        "        self.tokenizer = TOKENIZER\n",
        "        self.max_len = MAX_LEN\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        comment_text = str(self.comment_text[item])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            )\n",
        "\n",
        "        ids = inputs\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.float32,requires_grad=True),\n",
        "            'targets': torch.tensor(self.target[item])\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTDIAMDuIK16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing a BERT bert-base-uncased style configuration\n",
        "configuration = BertConfig()\n",
        "\n",
        "class BERTBaseUncased(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTBaseUncased, self).__init__()\n",
        "        self.bert = transformers.BertModel(configuration)\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768*2, 1)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        print(ids.shape)\n",
        "        print(ids)\n",
        "        o1, _ = self.bert(\n",
        "            input_ids=ids,\n",
        "            attention_mask=mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "\n",
        "        mean_pool = torch.mean(o1,1)\n",
        "        max_pool,_ = torch.max(o1,1)\n",
        "        cat = torch.cat((mean_pool, max_pool),1)\n",
        "\n",
        "        bo = self.bert_drop(cat)\n",
        "        output = self.out(bo)\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMwh4Qg2IK1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
        "\n",
        "\n",
        "def train_fn(data_loader, model, optimizer, device):\n",
        "    model.train()\n",
        "\n",
        "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "        ids = d[\"ids\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        targets = d[\"targets\"]\n",
        "\n",
        "\n",
        "\n",
        "        model.send(mask.location)\n",
        "        optimizer = optims.get_optim(mask.location.id)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(\n",
        "            ids=ids,\n",
        "            mask=mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        " \n",
        "\n",
        "\n",
        "def eval_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            ids = d[\"ids\"]\n",
        "            token_type_ids = d[\"token_type_ids\"]\n",
        "            mask = d[\"mask\"]\n",
        "            targets = d[\"targets\"]\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(\n",
        "                ids=ids,\n",
        "                mask=mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nggsABqKdlMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from syft.federated.floptimizer import Optims\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxibiBRxIK2B",
        "colab_type": "code",
        "outputId": "fdfa8112-1a25-4e63-b2e1-75eeccd3e8d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "def run():\n",
        "\n",
        "    df1 = pd.read_csv(\"data/jigsaw-toxic-comment-train.csv\", usecols=[\"comment_text\", \"toxic\"])\n",
        "    df2 = pd.read_csv(\"data/jigsaw-unintended-bias-train.csv\", usecols=[\"comment_text\", \"toxic\"])\n",
        "    \n",
        "    df_train = pd.concat([df1, df2], axis = 0).reset_index(drop = True)\n",
        "    \n",
        "    df_valid = pd.read_csv(\"data/validation.csv\")\n",
        "\n",
        "  \n",
        "\n",
        "    train_dataset = BERTDataset(\n",
        "        comment_text=df_train.comment_text.values,\n",
        "        target=df_train.toxic.values\n",
        "    )\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=TRAIN_BATCH_SIZE,\n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "    valid_dataset = BERTDataset(\n",
        "        comment_text=df_valid.comment_text.values,\n",
        "        target=df_valid.toxic.values\n",
        "    )\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=VALID_BATCH_SIZE,\n",
        "        num_workers=1\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    model = BERTBaseUncased()\n",
        "    model.to(device)\n",
        "    workers = ['bob', 'alice']\n",
        "    optims = Optims(workers, optim=optim.Adam(params=model.parameters(),lr=0.0001))\n",
        "    \n",
        "\n",
        "\n",
        "    best_accuracy = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_fn(train_data_loader, model, Optims, device)\n",
        "        outputs, targets = eval_fn(valid_data_loader, model, device)\n",
        "        targets = np.array(targets) >= 0.5\n",
        "        accuracy = metrics.roc_auc_score(targets, outputs)\n",
        "        print(f\"Accuracy Score = {accuracy}\")\n",
        "        if accuracy > best_accuracy:\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            best_accuracy = accuracy\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6092e45b9ae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-6092e45b9ae1>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/jigsaw-toxic-comment-train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment_text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toxic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/jigsaw-unintended-bias-train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment_text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toxic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \"\"\"\n\u001b[1;32m    544\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW1r_D_WMfyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]],dtype = torch.float32,\n",
        "                    requires_grad=True)\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qXe2whUg1dV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(data.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWszPF2Ig4fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.read_csv(\"data/jigsaw-toxic-comment-train.csv\", usecols=[\"comment_text\", \"toxic\"])\n",
        "df2 = pd.read_csv(\"data/jigsaw-unintended-bias-train.csv\", usecols=[\"comment_text\", \"toxic\"])\n",
        "\n",
        "df_train = pd.concat([df1, df2], axis = 0).reset_index(drop = True)\n",
        "\n",
        "df_valid = pd.read_csv(\"data/validation.csv\")\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = BERTDataset(\n",
        "    comment_text=df_train.comment_text.values,\n",
        "    target=df_train.toxic.values\n",
        ")\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=1,\n",
        "    num_workers=4\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBFUGZbQ8DWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "784c35bd-d61a-4326-e769-e37a467a9d0c"
      },
      "source": [
        "d= train_dataset[5]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-d600e8583013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-e2a62669060d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     20\u001b[0m             )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMyoy8GwwaIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d['']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTfoDVip9Ip7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = BERTBaseUncased()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icxza6Dr8lSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = d[\"ids\"]\n",
        "token_type_ids = d[\"token_type_ids\"]\n",
        "mask = d[\"mask\"]\n",
        "targets = d[\"targets\"]\n",
        "\n",
        "workers = ['bob', 'alice']\n",
        "optims = Optims(workers, optim=optim.Adam(params=model.parameters(),lr=0.0001))\n",
        "\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(params=model.parameters(),lr=0.0001)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "outputs = model(\n",
        "  \n",
        "    ids=ids,\n",
        "    mask=mask,\n",
        "    token_type_ids=token_type_ids\n",
        ")\n",
        "\n",
        "loss = loss_fn(outputs, targets)\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaEXhZKS9QJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "model=model.send(mask.location)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Odz46y3RMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "8c5a0875-0200-490e-b9f8-6f0a686c770c"
      },
      "source": [
        "optimizer = optims.get_optim(mask.location.id)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "outputs = model(\n",
        "  \n",
        "    ids=ids,\n",
        "    mask=mask,\n",
        "    token_type_ids=token_type_ids\n",
        ")\n",
        "\n",
        "loss = loss_fn(outputs, targets)\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([512])\n",
            "(Wrapper)>[PointerTensor | me:38092158836 -> bob:57770712249]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-a6fb6ec5e18b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-c011f51c7d4c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask, token_type_ids)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    723\u001b[0m             raise ValueError(\n\u001b[1;32m    724\u001b[0m                 \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n\u001b[0;32m--> 725\u001b[0;31m                     \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m                 )\n\u001b[1;32m    727\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong shape for input_ids (shape torch.Size([0])) or attention_mask (shape torch.Size([512]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6cei2T--N3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11UWv0XExZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel(configuration)\n",
        "\n",
        "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc9iFQOu8xmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids1=input_ids.send(bob)\n",
        "model1 = model.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwXp1EOD8u4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "58ce6a77-4887-4959-808f-3b49d1f7361a"
      },
      "source": [
        "outputs = model1(input_ids1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b3c63d5b100d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    723\u001b[0m             raise ValueError(\n\u001b[1;32m    724\u001b[0m                 \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n\u001b[0;32m--> 725\u001b[0;31m                     \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m                 )\n\u001b[1;32m    727\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong shape for input_ids (shape torch.Size([0])) or attention_mask (shape torch.Size([0]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfCLeLi6zClK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8620f09-7fa9-4dd3-ed20-a00258bf210b"
      },
      "source": [
        "bob.get_obj"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseWorker.get_obj of <VirtualWorker id:bob #objects:200>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K6ThzbL4uR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76d43760-2e6a-4393-839b-8ca158e11ec8"
      },
      "source": [
        "input_ids1.size()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG7Jjfy9615U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Dataset\n",
        "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
        "bobs_data = data.send(bob)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9F1PcAj_Ixs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce046b41-f9f7-45fa-c895-f3b79dd8946e"
      },
      "source": [
        "bobs_data.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA0iK5wP_LU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d62f7f39-85f3-427f-adbb-cba4153076f0"
      },
      "source": [
        "bobs_data.size()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSEAO0v-_PBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}