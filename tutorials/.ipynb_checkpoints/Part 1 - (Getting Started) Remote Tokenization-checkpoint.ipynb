{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Part 1 - (Getting Started) Remote Tokenization-checkpoint.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilanshrajput/OpenMined_Gsoc_Progress/blob/master/tutorials/.ipynb_checkpoints/Part%201%20-%20(Getting%20Started)%20Remote%20Tokenization-checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOckOJbWL4iB",
        "colab_type": "text"
      },
      "source": [
        "# Getting Started: Remote Tokenization\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUxcWkG5L4iE",
        "colab_type": "text"
      },
      "source": [
        "One of the main motivations behind the creation of SyferText is to provide the ability to preprocess strings residing on a remote machine. Tokenization is one such important preprocessing step when we create deep learning NLP models. \n",
        "\n",
        "SyferText leverages [PySyft](https://github.com/OpenMined/PySyft)'s distributed architecture and its privacy-preserving arsenal of tools to enable 'blind' tokenization of private strings residing on remote workers without revealing their contents.\n",
        "\n",
        "In this tutorial, you will learn how to use SyferText to tokenize a PySyft `String` residing on a remote private worker.\n",
        "\n",
        "A private worker is one whose data is considered as sensitive with restricted access. We do not have the right to read this data. SyferText enables us to 'blindly' tokenize such a string and get an encrypted version of its tokens' vector embeddings. With these encrypted embeddings, one could train an encrypted deep learning model using PySyft. \n",
        "\n",
        "Training an NLP model with encrypted embeddings will be the subject of an upcoming tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoTL1-VEL4iH",
        "colab_type": "text"
      },
      "source": [
        "#### Author\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDreNm4WL4iK",
        "colab_type": "text"
      },
      "source": [
        "- `Alan Aboudib`  -> [@alan_aboudib](https://twitter.com/alan_aboudib) (Twitter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJRDaNjfL4iN",
        "colab_type": "text"
      },
      "source": [
        "-----------------------\n",
        "\n",
        "## 1. `SyferText`'s distributed architecture\n",
        "\n",
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpFOn8twL4iP",
        "colab_type": "text"
      },
      "source": [
        "You have seen in a [previous tutorial](https://bit.ly/2RQ9lwl) that SyferText can be used to tokenize a PySyft string on a local worker. In such setting, all of the processing components such as the `Language`, `Tokenizer`, `Doc` and `Token` objects were created on the same worker.\n",
        "\n",
        "What you haven't seen yet is that SyferText's `Language` object can also be used to tokenize a PySyft `StringPointer` object, which is a pointer to a PySyft `String` on a remote worker.\n",
        "\n",
        "When the `Language` object receives a `StringPointer` to tokenize, some changes to its architecture are applied; some of its components are sent to the remote worker where the string lives. Here is how this is done:\n",
        "\n",
        "1. The `Language` object receives a `StringPointer` pointing to a PySyft `String` to be tokenized.\n",
        "2. A `Tokenizer` is created and sent to the worker where the `String` is.\n",
        "3. A `TokenizerPointer` object pointing to the remote `Tokenizer` is created and kept at the local worker.\n",
        "4. The remote tokenizer tokenizes the string on the remote worker and creates a `Doc` containing all of the `Token` objects.\n",
        "5. A `DocPointer` object pointing at the remote `Doc` is kept at the local worker.\n",
        "\n",
        "Here is an illustration of the steps I mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKTOPioIL4iS",
        "colab_type": "text"
      },
      "source": [
        "![SyferText architecture: local case](art/syfertext_remote.png \"SyferText architecture on remote workers\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lUrOseTL4iX",
        "colab_type": "text"
      },
      "source": [
        "Notice that the `DocPointer` in the illustration above does not provide access to the individual tokens as a `Doc` object does. This is because the string on the remote worker is considered as private; we are not allowed to reveal its tokens or bring them to our local machine. We are only allowed to obtain encrypted versions of them.\n",
        "\n",
        "Let's now do some coding:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ7Ox3vWL4iZ",
        "colab_type": "text"
      },
      "source": [
        "-----------------------\n",
        "\n",
        "## 2. Tokenizing a remote PySyft `String`\n",
        "\n",
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipkf-5xZL4ib",
        "colab_type": "text"
      },
      "source": [
        "Let's first import SyferText. Since SyferText is based on PySyft, we also need to import the latter, as well as PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUiCeD2EMr7h",
        "colab_type": "code",
        "outputId": "5d614598-0471-49d1-9dc3-8fb10ecca776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!git clone --single-branch --branch Lexeme https://github.com/Nilanshrajput/SyferText.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SyferText'...\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/141)\u001b[K\rremote: Counting objects:   1% (2/141)\u001b[K\rremote: Counting objects:   2% (3/141)\u001b[K\rremote: Counting objects:   3% (5/141)\u001b[K\rremote: Counting objects:   4% (6/141)\u001b[K\rremote: Counting objects:   5% (8/141)\u001b[K\rremote: Counting objects:   6% (9/141)\u001b[K\rremote: Counting objects:   7% (10/141)\u001b[K\rremote: Counting objects:   8% (12/141)\u001b[K\rremote: Counting objects:   9% (13/141)\u001b[K\rremote: Counting objects:  10% (15/141)\u001b[K\rremote: Counting objects:  11% (16/141)\u001b[K\rremote: Counting objects:  12% (17/141)\u001b[K\rremote: Counting objects:  13% (19/141)\u001b[K\rremote: Counting objects:  14% (20/141)\u001b[K\rremote: Counting objects:  15% (22/141)\u001b[K\rremote: Counting objects:  16% (23/141)\u001b[K\rremote: Counting objects:  17% (24/141)\u001b[K\rremote: Counting objects:  18% (26/141)\u001b[K\rremote: Counting objects:  19% (27/141)\u001b[K\rremote: Counting objects:  20% (29/141)\u001b[K\rremote: Counting objects:  21% (30/141)\u001b[K\rremote: Counting objects:  22% (32/141)\u001b[K\rremote: Counting objects:  23% (33/141)\u001b[K\rremote: Counting objects:  24% (34/141)\u001b[K\rremote: Counting objects:  25% (36/141)\u001b[K\rremote: Counting objects:  26% (37/141)\u001b[K\rremote: Counting objects:  27% (39/141)\u001b[K\rremote: Counting objects:  28% (40/141)\u001b[K\rremote: Counting objects:  29% (41/141)\u001b[K\rremote: Counting objects:  30% (43/141)\u001b[K\rremote: Counting objects:  31% (44/141)\u001b[K\rremote: Counting objects:  32% (46/141)\u001b[K\rremote: Counting objects:  33% (47/141)\u001b[K\rremote: Counting objects:  34% (48/141)\u001b[K\rremote: Counting objects:  35% (50/141)\u001b[K\rremote: Counting objects:  36% (51/141)\u001b[K\rremote: Counting objects:  37% (53/141)\u001b[K\rremote: Counting objects:  38% (54/141)\u001b[K\rremote: Counting objects:  39% (55/141)\u001b[K\rremote: Counting objects:  40% (57/141)\u001b[K\rremote: Counting objects:  41% (58/141)\u001b[K\rremote: Counting objects:  42% (60/141)\u001b[K\rremote: Counting objects:  43% (61/141)\u001b[K\rremote: Counting objects:  44% (63/141)\u001b[K\rremote: Counting objects:  45% (64/141)\u001b[K\rremote: Counting objects:  46% (65/141)\u001b[K\rremote: Counting objects:  47% (67/141)\u001b[K\rremote: Counting objects:  48% (68/141)\u001b[K\rremote: Counting objects:  49% (70/141)\u001b[K\rremote: Counting objects:  50% (71/141)\u001b[K\rremote: Counting objects:  51% (72/141)\u001b[K\rremote: Counting objects:  52% (74/141)\u001b[K\rremote: Counting objects:  53% (75/141)\u001b[K\rremote: Counting objects:  54% (77/141)\u001b[K\rremote: Counting objects:  55% (78/141)\u001b[K\rremote: Counting objects:  56% (79/141)\u001b[K\rremote: Counting objects:  57% (81/141)\u001b[K\rremote: Counting objects:  58% (82/141)\u001b[K\rremote: Counting objects:  59% (84/141)\u001b[K\rremote: Counting objects:  60% (85/141)\u001b[K\rremote: Counting objects:  61% (87/141)\u001b[K\rremote: Counting objects:  62% (88/141)\u001b[K\rremote: Counting objects:  63% (89/141)\u001b[K\rremote: Counting objects:  64% (91/141)\u001b[K\rremote: Counting objects:  65% (92/141)\u001b[K\rremote: Counting objects:  66% (94/141)\u001b[K\rremote: Counting objects:  67% (95/141)\u001b[K\rremote: Counting objects:  68% (96/141)\u001b[K\rremote: Counting objects:  69% (98/141)\u001b[K\rremote: Counting objects:  70% (99/141)\u001b[K\rremote: Counting objects:  71% (101/141)\rremote: Counting objects:  72% (102/141)\u001b[K\rremote: Counting objects:  73% (103/141)\u001b[K\rremote: Counting objects:  74% (105/141)\u001b[K\rremote: Counting objects:  75% (106/141)\u001b[K\rremote: Counting objects:  76% (108/141)\u001b[K\rremote: Counting objects:  77% (109/141)\u001b[K\rremote: Counting objects:  78% (110/141)\u001b[K\rremote: Counting objects:  79% (112/141)\u001b[K\rremote: Counting objects:  80% (113/141)\u001b[K\rremote: Counting objects:  81% (115/141)\u001b[K\rremote: Counting objects:  82% (116/141)\u001b[K\rremote: Counting objects:  83% (118/141)\u001b[K\rremote: Counting objects:  84% (119/141)\u001b[K\rremote: Counting objects:  85% (120/141)\u001b[K\rremote: Counting objects:  86% (122/141)\u001b[K\rremote: Counting objects:  87% (123/141)\u001b[K\rremote: Counting objects:  88% (125/141)\u001b[K\rremote: Counting objects:  89% (126/141)\u001b[K\rremote: Counting objects:  90% (127/141)\u001b[K\rremote: Counting objects:  91% (129/141)\u001b[K\rremote: Counting objects:  92% (130/141)\u001b[K\rremote: Counting objects:  93% (132/141)\u001b[K\rremote: Counting objects:  94% (133/141)\u001b[K\rremote: Counting objects:  95% (134/141)\u001b[K\rremote: Counting objects:  96% (136/141)\u001b[K\rremote: Counting objects:  97% (137/141)\u001b[K\rremote: Counting objects:  98% (139/141)\u001b[K\rremote: Counting objects:  99% (140/141)\u001b[K\rremote: Counting objects: 100% (141/141)\u001b[K\rremote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 1217 (delta 95), reused 88 (delta 53), pack-reused 1076\u001b[K\n",
            "Receiving objects: 100% (1217/1217), 388.78 KiB | 707.00 KiB/s, done.\n",
            "Resolving deltas: 100% (762/762), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9j49W6VMr4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r /content/SyferText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2tqSTudMrpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/SyferText')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tguh32pM7OZ",
        "colab_type": "code",
        "outputId": "26bd5a6b-9985-4695-976e-ee437d67c0e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'classifier'\n",
            "  warnings.warn(msg)\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating syfertext.egg-info\n",
            "writing syfertext.egg-info/PKG-INFO\n",
            "writing dependency_links to syfertext.egg-info/dependency_links.txt\n",
            "writing requirements to syfertext.egg-info/requires.txt\n",
            "writing top-level names to syfertext.egg-info/top_level.txt\n",
            "writing manifest file 'syfertext.egg-info/SOURCES.txt'\n",
            "writing manifest file 'syfertext.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/syfertext\n",
            "copying syfertext/vectors.py -> build/lib/syfertext\n",
            "copying syfertext/utils.py -> build/lib/syfertext\n",
            "copying syfertext/language.py -> build/lib/syfertext\n",
            "copying syfertext/doc.py -> build/lib/syfertext\n",
            "copying syfertext/__init__.py -> build/lib/syfertext\n",
            "copying syfertext/token_exception.py -> build/lib/syfertext\n",
            "copying syfertext/token.py -> build/lib/syfertext\n",
            "copying syfertext/string_store.py -> build/lib/syfertext\n",
            "copying syfertext/underscore.py -> build/lib/syfertext\n",
            "copying syfertext/char_classes.py -> build/lib/syfertext\n",
            "copying syfertext/tokenizer.py -> build/lib/syfertext\n",
            "copying syfertext/stop_words.py -> build/lib/syfertext\n",
            "copying syfertext/vocab.py -> build/lib/syfertext\n",
            "copying syfertext/punctuations.py -> build/lib/syfertext\n",
            "copying syfertext/lex_attrs.py -> build/lib/syfertext\n",
            "copying syfertext/lexeme.py -> build/lib/syfertext\n",
            "copying syfertext/attrs.py -> build/lib/syfertext\n",
            "creating build/lib/syfertext/pointers\n",
            "copying syfertext/pointers/__init__.py -> build/lib/syfertext/pointers\n",
            "copying syfertext/pointers/doc_pointer.py -> build/lib/syfertext/pointers\n",
            "creating build/lib/syfertext/pipeline\n",
            "copying syfertext/pipeline/subpipeline.py -> build/lib/syfertext/pipeline\n",
            "copying syfertext/pipeline/__init__.py -> build/lib/syfertext/pipeline\n",
            "copying syfertext/pipeline/simple_tagger.py -> build/lib/syfertext/pipeline\n",
            "creating build/lib/syfertext/pipeline/pointers\n",
            "copying syfertext/pipeline/pointers/subpipeline_pointer.py -> build/lib/syfertext/pipeline/pointers\n",
            "copying syfertext/pipeline/pointers/__init__.py -> build/lib/syfertext/pipeline/pointers\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/vectors.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/utils.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "creating build/bdist.linux-x86_64/egg/syfertext/pointers\n",
            "copying build/lib/syfertext/pointers/__init__.py -> build/bdist.linux-x86_64/egg/syfertext/pointers\n",
            "copying build/lib/syfertext/pointers/doc_pointer.py -> build/bdist.linux-x86_64/egg/syfertext/pointers\n",
            "copying build/lib/syfertext/language.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/doc.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/__init__.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/token_exception.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/token.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/string_store.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/underscore.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/char_classes.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/tokenizer.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/stop_words.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/vocab.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/punctuations.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/lex_attrs.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/lexeme.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "creating build/bdist.linux-x86_64/egg/syfertext/pipeline\n",
            "creating build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers\n",
            "copying build/lib/syfertext/pipeline/pointers/subpipeline_pointer.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers\n",
            "copying build/lib/syfertext/pipeline/pointers/__init__.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers\n",
            "copying build/lib/syfertext/pipeline/subpipeline.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline\n",
            "copying build/lib/syfertext/pipeline/__init__.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline\n",
            "copying build/lib/syfertext/pipeline/simple_tagger.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline\n",
            "copying build/lib/syfertext/attrs.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/vectors.py to vectors.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pointers/doc_pointer.py to doc_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/language.py to language.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/doc.py to doc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/token_exception.py to token_exception.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/token.py to token.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/string_store.py to string_store.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/underscore.py to underscore.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/char_classes.py to char_classes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/tokenizer.py to tokenizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/stop_words.py to stop_words.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/vocab.py to vocab.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/punctuations.py to punctuations.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/lex_attrs.py to lex_attrs.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/lexeme.py to lexeme.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers/subpipeline_pointer.py to subpipeline_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/subpipeline.py to subpipeline.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/simple_tagger.py to simple_tagger.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/attrs.py to attrs.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/syfertext-0.1.0.dev2-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing syfertext-0.1.0.dev2-py3.6.egg\n",
            "Removing /usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg\n",
            "Copying syfertext-0.1.0.dev2-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "syfertext 0.1.0.dev2 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg\n",
            "Processing dependencies for syfertext==0.1.0.dev2\n",
            "Searching for requests==2.22.0\n",
            "Best match: requests 2.22.0\n",
            "Processing requests-2.22.0-py3.6.egg\n",
            "requests 2.22.0 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/requests-2.22.0-py3.6.egg\n",
            "Searching for syft==0.2.4\n",
            "Best match: syft 0.2.4\n",
            "Processing syft-0.2.4-py3.6.egg\n",
            "syft 0.2.4 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/syft-0.2.4-py3.6.egg\n",
            "Searching for mmh3==2.5.1\n",
            "Best match: mmh3 2.5.1\n",
            "Processing mmh3-2.5.1-py3.6-linux-x86_64.egg\n",
            "mmh3 2.5.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/mmh3-2.5.1-py3.6-linux-x86_64.egg\n",
            "Searching for tqdm==4.36.1\n",
            "Best match: tqdm 4.36.1\n",
            "Processing tqdm-4.36.1-py3.6.egg\n",
            "tqdm 4.36.1 is already the active version in easy-install.pth\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/tqdm-4.36.1-py3.6.egg\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.8\n",
            "Best match: idna 2.8\n",
            "Adding idna 2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2020.4.5.1\n",
            "Best match: certifi 2020.4.5.1\n",
            "Adding certifi 2020.4.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websockets==8.1\n",
            "Best match: websockets 8.1\n",
            "Processing websockets-8.1-py3.6-linux-x86_64.egg\n",
            "websockets 8.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/websockets-8.1-py3.6-linux-x86_64.egg\n",
            "Searching for websocket-client==0.57.0\n",
            "Best match: websocket-client 0.57.0\n",
            "Processing websocket_client-0.57.0-py3.6.egg\n",
            "websocket-client 0.57.0 is already the active version in easy-install.pth\n",
            "Installing wsdump.py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/websocket_client-0.57.0-py3.6.egg\n",
            "Searching for tornado==4.5.3\n",
            "Best match: tornado 4.5.3\n",
            "Adding tornado 4.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.4.0\n",
            "Best match: torch 1.4.0\n",
            "Adding torch 1.4.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torchvision==0.5.0\n",
            "Best match: torchvision 0.5.0\n",
            "Adding torchvision 0.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tblib==1.6.0\n",
            "Best match: tblib 1.6.0\n",
            "Adding tblib 1.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for syft-proto==0.2.5a1\n",
            "Best match: syft-proto 0.2.5a1\n",
            "Processing syft_proto-0.2.5a1-py3.6.egg\n",
            "syft-proto 0.2.5a1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/syft_proto-0.2.5a1-py3.6.egg\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for phe==1.4.0\n",
            "Best match: phe 1.4.0\n",
            "Processing phe-1.4.0-py3.6.egg\n",
            "phe 1.4.0 is already the active version in easy-install.pth\n",
            "Installing pheutil script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/phe-1.4.0-py3.6.egg\n",
            "Searching for numpy==1.18.2\n",
            "Best match: numpy 1.18.2\n",
            "Adding numpy 1.18.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for msgpack==1.0.0\n",
            "Best match: msgpack 1.0.0\n",
            "Adding msgpack 1.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lz4==3.0.2\n",
            "Best match: lz4 3.0.2\n",
            "Processing lz4-3.0.2-py3.6-linux-x86_64.egg\n",
            "lz4 3.0.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/lz4-3.0.2-py3.6-linux-x86_64.egg\n",
            "Searching for Flask-SocketIO==4.2.1\n",
            "Best match: Flask-SocketIO 4.2.1\n",
            "Processing Flask_SocketIO-4.2.1-py3.6.egg\n",
            "Flask-SocketIO 4.2.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/Flask_SocketIO-4.2.1-py3.6.egg\n",
            "Searching for Pillow==6.2.2\n",
            "Best match: Pillow 6.2.2\n",
            "Processing Pillow-6.2.2-py3.6-linux-x86_64.egg\n",
            "Pillow 6.2.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/Pillow-6.2.2-py3.6-linux-x86_64.egg\n",
            "Searching for Flask==1.1.2\n",
            "Best match: Flask 1.1.2\n",
            "Adding Flask 1.1.2 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.11.3\n",
            "Best match: protobuf 3.11.3\n",
            "Processing protobuf-3.11.3-py3.6-linux-x86_64.egg\n",
            "protobuf 3.11.3 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/protobuf-3.11.3-py3.6-linux-x86_64.egg\n",
            "Searching for python-socketio==4.5.1\n",
            "Best match: python-socketio 4.5.1\n",
            "Processing python_socketio-4.5.1-py3.6.egg\n",
            "python-socketio 4.5.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/python_socketio-4.5.1-py3.6.egg\n",
            "Searching for click==7.1.1\n",
            "Best match: click 7.1.1\n",
            "Adding click 7.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Jinja2==2.11.1\n",
            "Best match: Jinja2 2.11.1\n",
            "Adding Jinja2 2.11.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==46.1.3\n",
            "Best match: setuptools 46.1.3\n",
            "Adding setuptools 46.1.3 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-engineio==3.12.1\n",
            "Best match: python-engineio 3.12.1\n",
            "Processing python_engineio-3.12.1-py3.6.egg\n",
            "python-engineio 3.12.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/python_engineio-3.12.1-py3.6.egg\n",
            "Searching for MarkupSafe==1.1.1\n",
            "Best match: MarkupSafe 1.1.1\n",
            "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for syfertext==0.1.0.dev2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpQH2yapL4id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hide warnings (nothing to do with SyferText)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c9uMU_OL4io",
        "colab_type": "code",
        "outputId": "2ab28210-0017-4aa7-fc2e-2fed1fd50b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import syft as sy\n",
        "import torch\n",
        "import syfertext\n",
        "\n",
        "# Import PySyft's String class\n",
        "from syft.generic.string import String"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Torch was already hooked... skipping hooking process\n",
            "WARNING:root:Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u39hP2eLL4iy",
        "colab_type": "text"
      },
      "source": [
        "We now need to hook PyTorch using the TorchHook in PySyft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtwfGFcWL4i0",
        "colab_type": "code",
        "outputId": "5b620aa5-13ee-4350-e300-abf163294c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hook = sy.TorchHook(torch)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY0Qnl2YL4i9",
        "colab_type": "text"
      },
      "source": [
        "This will endow PyTorch with magic powers, privacy-preserving deep learning powers, such as Federated Learning, Differential Privacy, Encrypted Training tools and more. To learn more about PySyft, you can check out its awesome [tutorial notebooks](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcAZk7-tL4i_",
        "colab_type": "text"
      },
      "source": [
        "Every machine in PySyft is called a worker. Since we are using SyferText to tokenize a string on a remote machine, then we should get an instance of the object representing that worker. So let's now create fours workers. We will call the local worker 'me', and the remote workers 'bob' and 'alice'. A fourth worker that will act as the crypto provider for SMPC, the encryption algorithm PySyft uses, should also be created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkh24cciL4jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The local worker\n",
        "me = hook.local_worker\n",
        "\n",
        "# The remote workers\n",
        "bob = sy.VirtualWorker(hook, id = 'bob')\n",
        "alice = sy.VirtualWorker(hook, id = 'alice')\n",
        "\n",
        "# The crypto provider\n",
        "crypto_provider = sy.VirtualWorker(hook, id = 'crypto_provider')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0hrcKXwL4jL",
        "colab_type": "text"
      },
      "source": [
        "We are now ready to load the language model. The only language model available for the moment in SyferText is `en_core_web_lg`, which is a model for English language simplified from spaCy's language model with the same name. Check out the  properties of that model [here](https://spacy.io/models/en#en_core_web_lg)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ai6ONu3L4jM",
        "colab_type": "code",
        "outputId": "23e60b3f-2bd1-484c-8f10-81b8cf8fbe84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nlp = syfertext.load('en_core_web_lg', owner = me)\n",
        "\n",
        "type(nlp), nlp.owner"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(syfertext.language.Language, <VirtualWorker id:me #objects:0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9k7HYCvZ-Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"sbsg sdg sddgerh dfhbherh dsthth vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv sfdbndf dfher ergerg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC7pLVHDbIlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lex = nlp.vocab[\"fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX7eLZpgZ-JO",
        "colab_type": "code",
        "outputId": "13c096cf-b9fe-44fd-e6b4-483594f6bd16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "sys.getsizeof(lex)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qswrI75xZ-Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOvjk3toZ-B5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzqAF7N0L4jU",
        "colab_type": "text"
      },
      "source": [
        "Notice from the cell's output that the `nlp` variable is an object of the `Language` class, and similar to all PySyft objects, it has an owner, which is a PySyft `VirtualWorker` representing our local machine. This corresponds to the illustration I showed you above were the `Language` object was shown to reside in the local worker."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKzPyhALL4jW",
        "colab_type": "text"
      },
      "source": [
        "We are now going to create a PySyft `String` and send it to `bob`. This will be our remote string that we are going to tokenize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3nwYAUDL4jX",
        "colab_type": "code",
        "outputId": "05ae25c1-82f8-4bd1-bdd0-f36eee7d913d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "string = String('A string to tokenize')\n",
        "\n",
        "# Send the string to the remote worker `bob`\n",
        "string_ptr = string.send(bob)\n",
        "\n",
        "type(string_ptr)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "syft.generic.pointers.string_pointer.StringPointer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxJLxzL2L4jh",
        "colab_type": "text"
      },
      "source": [
        "Notice that the variable `string_ptr` is a `StringPointer` object returned by the `send()` method of the worker object. Let's make sure that the string is really sent to bob."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xzGoNl3Njec",
        "colab_type": "code",
        "outputId": "4087bfac-ef63-4871-9048-0eb5bdcff0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(string_ptr.location)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<VirtualWorker id:bob #objects:1>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f94msyPQL4jj",
        "colab_type": "code",
        "outputId": "46ed9650-c9bc-464d-a8af-624168b4d984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "bob._objects"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{42866714656: 'A string to tokenize'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i8GzVhRL4jr",
        "colab_type": "text"
      },
      "source": [
        "Notice that `bob`'s object store now includes the PySyft string we are willing to tokenizer.\n",
        "\n",
        "You might have noticed that printing out the `_objects` attribute has actually revealed the string text. This of course violates our assumption that the remote string is private. This is one main developement issue SyferText is going to integrate in the near future.\n",
        "\n",
        "We now have all what we need to tokenize the string. Let's do it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk_LJu8fL4js",
        "colab_type": "code",
        "outputId": "0a42b7d6-1c18-4348-f9d6-ca2a7f9409ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "doc_ptr = nlp(string_ptr)\n",
        "\n",
        "# Some checks\n",
        "print(type(doc_ptr))\n",
        "print(doc_ptr)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'syfertext.pointers.doc_pointer.DocPointer'>\n",
            "[DocPointer | me:33924251660 -> bob:65026310212]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-WQdlFBL4j0",
        "colab_type": "text"
      },
      "source": [
        "From the above output, you can see that calling `nlp` with the `StringPointer` as its argument returns a `DocPointer` object that points to a `Doc` with a specified ID residing on `bob`, the remote worker.\n",
        "\n",
        "Let's check out if `bob` really has a `Doc` object with that ID:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbxBCXmKL4j2",
        "colab_type": "code",
        "outputId": "d21e9896-71e3-4184-a454-0ee1985af88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{26268072781: SubPipeline[tokenizer],\n",
              " 42866714656: 'A string to tokenize',\n",
              " 65026310212: Doc>None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OpvA2pML4kB",
        "colab_type": "text"
      },
      "source": [
        "It does! `bob` has a `Doc` with the same ID specified by the `DocPointer` printout above. Moreover, the `Tokenizer` also resides on `bob` which is what you saw in the above illustration of SyferText's architecture at the beginning of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulW736ngL4kB",
        "colab_type": "text"
      },
      "source": [
        "Using that `DocPointer` we can now get an SMPC-encrypted string vector. For the moment, the string vector here is simply a concatenation of the individual token vectors of the string. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLsUx4AjUqU",
        "colab_type": "code",
        "outputId": "cdbf3cb4-dd71-4ba4-e1f2-aa091c0d7e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc_vector_enc = doc_ptr.get_encrypted_vector(bob, alice, crypto_provider = crypto_provider)\n",
        "type(doc_ptr)\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "syfertext.pointers.doc_pointer.DocPointer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrmZAyAXL4kG",
        "colab_type": "code",
        "outputId": "8b96c56d-d5f8-42b6-a68b-b5d8155f4ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "doc_vector_enc = doc_ptr.get_encrypted_vector(bob, alice, crypto_provider = crypto_provider)\n",
        "\n",
        "print(f' Vector size is {doc_vector_enc.shape[0]}')\n",
        "print(doc_vector_enc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Vector size is 300\n",
            "(Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
            "\t-> [PointerTensor | me:48839578744 -> bob:20356139908]\n",
            "\t-> [PointerTensor | me:60681750582 -> alice:73334513090]\n",
            "\t*crypto provider: crypto_provider*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJPXXq4KL4kM",
        "colab_type": "text"
      },
      "source": [
        "As expected, the returned vector is an SMPC-encrypted PySyft `AdditiveSharingTensor` object. It is encrypted into two shares residing in `bob` and `alice` workers. It has a size of 1200 which corresponds to the size of 4 concatentated token vectors each of size 300.\n",
        "\n",
        "Accessing individual token attributes (within the limits of available access rights) through a `DocPointer` object is not implemented yet, but it will soon be. Please check out [this tutorial](https://bit.ly/2RQ9lwl) on local string tokenization to see how individual tokens can be accessed using a `Doc` object. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1AjjWLcL4kO",
        "colab_type": "text"
      },
      "source": [
        "### That's it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDo_6fxwL4kP",
        "colab_type": "text"
      },
      "source": [
        "You now know how to use SyferText to tokenize a remote string by manipulating a string pointer. You have seen how SyferText's distributed architecture make that easy by leveraging PySyft which, in turn, handles all the communication logic between workers.\n",
        "\n",
        "However, since SyferText is still in its developement phase, more features and methods are constantly being added and/or modified. We will make sure to update this tutorial whenever such new features are released."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1PynIBVL4kQ",
        "colab_type": "text"
      },
      "source": [
        "If you have any questions or suggestions, you can DM me on OpenMined's [slack channel](http://slack.openmined.org/), or otherwise contact me directly on my [Twitter page](https://twitter.com/alan_aboudib)."
      ]
    }
  ]
}