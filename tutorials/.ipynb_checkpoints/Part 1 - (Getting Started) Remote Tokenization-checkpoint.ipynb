{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Part 1 - (Getting Started) Remote Tokenization-checkpoint.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilanshrajput/OpenMined_Gsoc_Progress/blob/master/tutorials/.ipynb_checkpoints/Part%201%20-%20(Getting%20Started)%20Remote%20Tokenization-checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOckOJbWL4iB",
        "colab_type": "text"
      },
      "source": [
        "# Getting Started: Remote Tokenization\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUxcWkG5L4iE",
        "colab_type": "text"
      },
      "source": [
        "One of the main motivations behind the creation of SyferText is to provide the ability to preprocess strings residing on a remote machine. Tokenization is one such important preprocessing step when we create deep learning NLP models. \n",
        "\n",
        "SyferText leverages [PySyft](https://github.com/OpenMined/PySyft)'s distributed architecture and its privacy-preserving arsenal of tools to enable 'blind' tokenization of private strings residing on remote workers without revealing their contents.\n",
        "\n",
        "In this tutorial, you will learn how to use SyferText to tokenize a PySyft `String` residing on a remote private worker.\n",
        "\n",
        "A private worker is one whose data is considered as sensitive with restricted access. We do not have the right to read this data. SyferText enables us to 'blindly' tokenize such a string and get an encrypted version of its tokens' vector embeddings. With these encrypted embeddings, one could train an encrypted deep learning model using PySyft. \n",
        "\n",
        "Training an NLP model with encrypted embeddings will be the subject of an upcoming tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoTL1-VEL4iH",
        "colab_type": "text"
      },
      "source": [
        "#### Author\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDreNm4WL4iK",
        "colab_type": "text"
      },
      "source": [
        "- `Alan Aboudib`  -> [@alan_aboudib](https://twitter.com/alan_aboudib) (Twitter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJRDaNjfL4iN",
        "colab_type": "text"
      },
      "source": [
        "-----------------------\n",
        "\n",
        "## 1. `SyferText`'s distributed architecture\n",
        "\n",
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpFOn8twL4iP",
        "colab_type": "text"
      },
      "source": [
        "You have seen in a [previous tutorial](https://bit.ly/2RQ9lwl) that SyferText can be used to tokenize a PySyft string on a local worker. In such setting, all of the processing components such as the `Language`, `Tokenizer`, `Doc` and `Token` objects were created on the same worker.\n",
        "\n",
        "What you haven't seen yet is that SyferText's `Language` object can also be used to tokenize a PySyft `StringPointer` object, which is a pointer to a PySyft `String` on a remote worker.\n",
        "\n",
        "When the `Language` object receives a `StringPointer` to tokenize, some changes to its architecture are applied; some of its components are sent to the remote worker where the string lives. Here is how this is done:\n",
        "\n",
        "1. The `Language` object receives a `StringPointer` pointing to a PySyft `String` to be tokenized.\n",
        "2. A `Tokenizer` is created and sent to the worker where the `String` is.\n",
        "3. A `TokenizerPointer` object pointing to the remote `Tokenizer` is created and kept at the local worker.\n",
        "4. The remote tokenizer tokenizes the string on the remote worker and creates a `Doc` containing all of the `Token` objects.\n",
        "5. A `DocPointer` object pointing at the remote `Doc` is kept at the local worker.\n",
        "\n",
        "Here is an illustration of the steps I mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKTOPioIL4iS",
        "colab_type": "text"
      },
      "source": [
        "![SyferText architecture: local case](art/syfertext_remote.png \"SyferText architecture on remote workers\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lUrOseTL4iX",
        "colab_type": "text"
      },
      "source": [
        "Notice that the `DocPointer` in the illustration above does not provide access to the individual tokens as a `Doc` object does. This is because the string on the remote worker is considered as private; we are not allowed to reveal its tokens or bring them to our local machine. We are only allowed to obtain encrypted versions of them.\n",
        "\n",
        "Let's now do some coding:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ7Ox3vWL4iZ",
        "colab_type": "text"
      },
      "source": [
        "-----------------------\n",
        "\n",
        "## 2. Tokenizing a remote PySyft `String`\n",
        "\n",
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipkf-5xZL4ib",
        "colab_type": "text"
      },
      "source": [
        "Let's first import SyferText. Since SyferText is based on PySyft, we also need to import the latter, as well as PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUiCeD2EMr7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "cafc40fc-68e7-4201-d8d1-5de22cfcb6c2"
      },
      "source": [
        "!git clone --single-branch --branch Lexeme https://github.com/Nilanshrajput/SyferText.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SyferText'...\n",
            "remote: Enumerating objects: 132, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/132)\u001b[K\rremote: Counting objects:   1% (2/132)\u001b[K\rremote: Counting objects:   2% (3/132)\u001b[K\rremote: Counting objects:   3% (4/132)\u001b[K\rremote: Counting objects:   4% (6/132)\u001b[K\rremote: Counting objects:   5% (7/132)\u001b[K\rremote: Counting objects:   6% (8/132)\u001b[K\rremote: Counting objects:   7% (10/132)\u001b[K\rremote: Counting objects:   8% (11/132)\u001b[K\rremote: Counting objects:   9% (12/132)\u001b[K\rremote: Counting objects:  10% (14/132)\u001b[K\rremote: Counting objects:  11% (15/132)\u001b[K\rremote: Counting objects:  12% (16/132)\u001b[K\rremote: Counting objects:  13% (18/132)\u001b[K\rremote: Counting objects:  14% (19/132)\u001b[K\rremote: Counting objects:  15% (20/132)\u001b[K\rremote: Counting objects:  16% (22/132)\u001b[K\rremote: Counting objects:  17% (23/132)\u001b[K\rremote: Counting objects:  18% (24/132)\u001b[K\rremote: Counting objects:  19% (26/132)\u001b[K\rremote: Counting objects:  20% (27/132)\u001b[K\rremote: Counting objects:  21% (28/132)\u001b[K\rremote: Counting objects:  22% (30/132)\u001b[K\rremote: Counting objects:  23% (31/132)\u001b[K\rremote: Counting objects:  24% (32/132)\u001b[K\rremote: Counting objects:  25% (33/132)\u001b[K\rremote: Counting objects:  26% (35/132)\u001b[K\rremote: Counting objects:  27% (36/132)\u001b[K\rremote: Counting objects:  28% (37/132)\u001b[K\rremote: Counting objects:  29% (39/132)\u001b[K\rremote: Counting objects:  30% (40/132)\u001b[K\rremote: Counting objects:  31% (41/132)\u001b[K\rremote: Counting objects:  32% (43/132)\u001b[K\rremote: Counting objects:  33% (44/132)\u001b[K\rremote: Counting objects:  34% (45/132)\u001b[K\rremote: Counting objects:  35% (47/132)\u001b[K\rremote: Counting objects:  36% (48/132)\u001b[K\rremote: Counting objects:  37% (49/132)\u001b[K\rremote: Counting objects:  38% (51/132)\u001b[K\rremote: Counting objects:  39% (52/132)\u001b[K\rremote: Counting objects:  40% (53/132)\u001b[K\rremote: Counting objects:  41% (55/132)\u001b[K\rremote: Counting objects:  42% (56/132)\u001b[K\rremote: Counting objects:  43% (57/132)\u001b[K\rremote: Counting objects:  44% (59/132)\u001b[K\rremote: Counting objects:  45% (60/132)\u001b[K\rremote: Counting objects:  46% (61/132)\u001b[K\rremote: Counting objects:  47% (63/132)\u001b[K\rremote: Counting objects:  48% (64/132)\u001b[K\rremote: Counting objects:  49% (65/132)\u001b[K\rremote: Counting objects:  50% (66/132)\u001b[K\rremote: Counting objects:  51% (68/132)\u001b[K\rremote: Counting objects:  52% (69/132)\u001b[K\rremote: Counting objects:  53% (70/132)\u001b[K\rremote: Counting objects:  54% (72/132)\u001b[K\rremote: Counting objects:  55% (73/132)\u001b[K\rremote: Counting objects:  56% (74/132)\u001b[K\rremote: Counting objects:  57% (76/132)\u001b[K\rremote: Counting objects:  58% (77/132)\u001b[K\rremote: Counting objects:  59% (78/132)\u001b[K\rremote: Counting objects:  60% (80/132)\u001b[K\rremote: Counting objects:  61% (81/132)\u001b[K\rremote: Counting objects:  62% (82/132)\u001b[K\rremote: Counting objects:  63% (84/132)\u001b[K\rremote: Counting objects:  64% (85/132)\u001b[K\rremote: Counting objects:  65% (86/132)\u001b[K\rremote: Counting objects:  66% (88/132)\u001b[K\rremote: Counting objects:  67% (89/132)\u001b[K\rremote: Counting objects:  68% (90/132)\u001b[K\rremote: Counting objects:  69% (92/132)\u001b[K\rremote: Counting objects:  70% (93/132)\u001b[K\rremote: Counting objects:  71% (94/132)\u001b[K\rremote: Counting objects:  72% (96/132)\u001b[K\rremote: Counting objects:  73% (97/132)\u001b[K\rremote: Counting objects:  74% (98/132)\u001b[K\rremote: Counting objects:  75% (99/132)\u001b[K\rremote: Counting objects:  76% (101/132)\u001b[K\rremote: Counting objects:  77% (102/132)\u001b[K\rremote: Counting objects:  78% (103/132)\u001b[K\rremote: Counting objects:  79% (105/132)\u001b[K\rremote: Counting objects:  80% (106/132)\u001b[K\rremote: Counting objects:  81% (107/132)\u001b[K\rremote: Counting objects:  82% (109/132)\u001b[K\rremote: Counting objects:  83% (110/132)\u001b[K\rremote: Counting objects:  84% (111/132)\u001b[K\rremote: Counting objects:  85% (113/132)\u001b[K\rremote: Counting objects:  86% (114/132)\u001b[K\rremote: Counting objects:  87% (115/132)\u001b[K\rremote: Counting objects:  88% (117/132)\u001b[K\rremote: Counting objects:  89% (118/132)\u001b[K\rremote: Counting objects:  90% (119/132)\u001b[K\rremote: Counting objects:  91% (121/132)\u001b[K\rremote: Counting objects:  92% (122/132)\u001b[K\rremote: Counting objects:  93% (123/132)\u001b[K\rremote: Counting objects:  94% (125/132)\u001b[K\rremote: Counting objects:  95% (126/132)\u001b[K\rremote: Counting objects:  96% (127/132)\u001b[K\rremote: Counting objects:  97% (129/132)\u001b[K\rremote: Counting objects:  98% (130/132)\u001b[K\rremote: Counting objects:  99% (131/132)\u001b[K\rremote: Counting objects: 100% (132/132)\u001b[K\rremote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/80)\u001b[K\rremote: Compressing objects:   2% (2/80)\u001b[K\rremote: Compressing objects:   3% (3/80)\u001b[K\rremote: Compressing objects:   5% (4/80)\u001b[K\rremote: Compressing objects:   6% (5/80)\u001b[K\rremote: Compressing objects:   7% (6/80)\u001b[K\rremote: Compressing objects:   8% (7/80)\u001b[K\rremote: Compressing objects:  10% (8/80)\u001b[K\rremote: Compressing objects:  11% (9/80)\u001b[K\rremote: Compressing objects:  12% (10/80)\u001b[K\rremote: Compressing objects:  13% (11/80)\u001b[K\rremote: Compressing objects:  15% (12/80)\u001b[K\rremote: Compressing objects:  16% (13/80)\u001b[K\rremote: Compressing objects:  17% (14/80)\u001b[K\rremote: Compressing objects:  18% (15/80)\u001b[K\rremote: Compressing objects:  20% (16/80)\u001b[K\rremote: Compressing objects:  21% (17/80)\u001b[K\rremote: Compressing objects:  22% (18/80)\u001b[K\rremote: Compressing objects:  23% (19/80)\u001b[K\rremote: Compressing objects:  25% (20/80)\u001b[K\rremote: Compressing objects:  26% (21/80)\u001b[K\rremote: Compressing objects:  27% (22/80)\u001b[K\rremote: Compressing objects:  28% (23/80)\u001b[K\rremote: Compressing objects:  30% (24/80)\u001b[K\rremote: Compressing objects:  31% (25/80)\u001b[K\rremote: Compressing objects:  32% (26/80)\u001b[K\rremote: Compressing objects:  33% (27/80)\u001b[K\rremote: Compressing objects:  35% (28/80)\u001b[K\rremote: Compressing objects:  36% (29/80)\u001b[K\rremote: Compressing objects:  37% (30/80)\u001b[K\rremote: Compressing objects:  38% (31/80)\u001b[K\rremote: Compressing objects:  40% (32/80)\u001b[K\rremote: Compressing objects:  41% (33/80)\u001b[K\rremote: Compressing objects:  42% (34/80)\u001b[K\rremote: Compressing objects:  43% (35/80)\u001b[K\rremote: Compressing objects:  45% (36/80)\u001b[K\rremote: Compressing objects:  46% (37/80)\u001b[K\rremote: Compressing objects:  47% (38/80)\u001b[K\rremote: Compressing objects:  48% (39/80)\u001b[K\rremote: Compressing objects:  50% (40/80)\u001b[K\rremote: Compressing objects:  51% (41/80)\u001b[K\rremote: Compressing objects:  52% (42/80)\u001b[K\rremote: Compressing objects:  53% (43/80)\u001b[K\rremote: Compressing objects:  55% (44/80)\u001b[K\rremote: Compressing objects:  56% (45/80)\u001b[K\rremote: Compressing objects:  57% (46/80)\u001b[K\rremote: Compressing objects:  58% (47/80)\u001b[K\rremote: Compressing objects:  60% (48/80)\u001b[K\rremote: Compressing objects:  61% (49/80)\u001b[K\rremote: Compressing objects:  62% (50/80)\u001b[K\rremote: Compressing objects:  63% (51/80)\u001b[K\rremote: Compressing objects:  65% (52/80)\u001b[K\rremote: Compressing objects:  66% (53/80)\u001b[K\rremote: Compressing objects:  67% (54/80)\u001b[K\rremote: Compressing objects:  68% (55/80)\u001b[K\rremote: Compressing objects:  70% (56/80)\u001b[K\rremote: Compressing objects:  71% (57/80)\u001b[K\rremote: Compressing objects:  72% (58/80)\u001b[K\rremote: Compressing objects:  73% (59/80)\u001b[K\rremote: Compressing objects:  75% (60/80)\u001b[K\rremote: Compressing objects:  76% (61/80)\u001b[K\rremote: Compressing objects:  77% (62/80)\u001b[K\rremote: Compressing objects:  78% (63/80)\u001b[K\rremote: Compressing objects:  80% (64/80)\u001b[K\rremote: Compressing objects:  81% (65/80)\u001b[K\rremote: Compressing objects:  82% (66/80)\u001b[K\rremote: Compressing objects:  83% (67/80)\u001b[K\rremote: Compressing objects:  85% (68/80)\u001b[K\rremote: Compressing objects:  86% (69/80)\u001b[K\rremote: Compressing objects:  87% (70/80)\u001b[K\rremote: Compressing objects:  88% (71/80)\u001b[K\rremote: Compressing objects:  90% (72/80)\u001b[K\rremote: Compressing objects:  91% (73/80)\u001b[K\rremote: Compressing objects:  92% (74/80)\u001b[K\rremote: Compressing objects:  93% (75/80)\u001b[K\rremote: Compressing objects:  95% (76/80)\u001b[K\rremote: Compressing objects:  96% (77/80)\u001b[K\rremote: Compressing objects:  97% (78/80)\u001b[K\rremote: Compressing objects:  98% (79/80)\u001b[K\rremote: Compressing objects: 100% (80/80)\u001b[K\rremote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "Receiving objects:   0% (1/1208)   \rReceiving objects:   1% (13/1208)   \rReceiving objects:   2% (25/1208)   \rReceiving objects:   3% (37/1208)   \rReceiving objects:   4% (49/1208)   \rReceiving objects:   5% (61/1208)   \rReceiving objects:   6% (73/1208)   \rReceiving objects:   7% (85/1208)   \rReceiving objects:   8% (97/1208)   \rReceiving objects:   9% (109/1208)   \rReceiving objects:  10% (121/1208)   \rReceiving objects:  11% (133/1208)   \rReceiving objects:  12% (145/1208)   \rReceiving objects:  13% (158/1208)   \rReceiving objects:  14% (170/1208)   \rReceiving objects:  15% (182/1208)   \rReceiving objects:  16% (194/1208)   \rReceiving objects:  17% (206/1208)   \rReceiving objects:  18% (218/1208)   \rReceiving objects:  19% (230/1208)   \rReceiving objects:  20% (242/1208)   \rReceiving objects:  21% (254/1208)   \rReceiving objects:  22% (266/1208)   \rReceiving objects:  23% (278/1208)   \rReceiving objects:  24% (290/1208)   \rReceiving objects:  25% (302/1208)   \rReceiving objects:  26% (315/1208)   \rReceiving objects:  27% (327/1208)   \rReceiving objects:  28% (339/1208)   \rReceiving objects:  29% (351/1208)   \rReceiving objects:  30% (363/1208)   \rReceiving objects:  31% (375/1208)   \rReceiving objects:  32% (387/1208)   \rReceiving objects:  33% (399/1208)   \rReceiving objects:  34% (411/1208)   \rReceiving objects:  35% (423/1208)   \rReceiving objects:  36% (435/1208)   \rReceiving objects:  37% (447/1208)   \rReceiving objects:  38% (460/1208)   \rReceiving objects:  39% (472/1208)   \rReceiving objects:  40% (484/1208)   \rReceiving objects:  41% (496/1208)   \rReceiving objects:  42% (508/1208)   \rReceiving objects:  43% (520/1208)   \rReceiving objects:  44% (532/1208)   \rReceiving objects:  45% (544/1208)   \rReceiving objects:  46% (556/1208)   \rReceiving objects:  47% (568/1208)   \rReceiving objects:  48% (580/1208)   \rReceiving objects:  49% (592/1208)   \rReceiving objects:  50% (604/1208)   \rReceiving objects:  51% (617/1208)   \rReceiving objects:  52% (629/1208)   \rReceiving objects:  53% (641/1208)   \rReceiving objects:  54% (653/1208)   \rReceiving objects:  55% (665/1208)   \rReceiving objects:  56% (677/1208)   \rReceiving objects:  57% (689/1208)   \rReceiving objects:  58% (701/1208)   \rReceiving objects:  59% (713/1208)   \rReceiving objects:  60% (725/1208)   \rReceiving objects:  61% (737/1208)   \rReceiving objects:  62% (749/1208)   \rReceiving objects:  63% (762/1208)   \rReceiving objects:  64% (774/1208)   \rReceiving objects:  65% (786/1208)   \rReceiving objects:  66% (798/1208)   \rReceiving objects:  67% (810/1208)   \rReceiving objects:  68% (822/1208)   \rReceiving objects:  69% (834/1208)   \rReceiving objects:  70% (846/1208)   \rReceiving objects:  71% (858/1208)   \rReceiving objects:  72% (870/1208)   \rReceiving objects:  73% (882/1208)   \rReceiving objects:  74% (894/1208)   \rReceiving objects:  75% (906/1208)   \rReceiving objects:  76% (919/1208)   \rReceiving objects:  77% (931/1208)   \rReceiving objects:  78% (943/1208)   \rReceiving objects:  79% (955/1208)   \rReceiving objects:  80% (967/1208)   \rReceiving objects:  81% (979/1208)   \rReceiving objects:  82% (991/1208)   \rReceiving objects:  83% (1003/1208)   \rReceiving objects:  84% (1015/1208)   \rReceiving objects:  85% (1027/1208)   \rremote: Total 1208 (delta 88), reused 83 (delta 52), pack-reused 1076\u001b[K\n",
            "Receiving objects:  86% (1039/1208)   \rReceiving objects:  87% (1051/1208)   \rReceiving objects:  88% (1064/1208)   \rReceiving objects:  89% (1076/1208)   \rReceiving objects:  90% (1088/1208)   \rReceiving objects:  91% (1100/1208)   \rReceiving objects:  92% (1112/1208)   \rReceiving objects:  93% (1124/1208)   \rReceiving objects:  94% (1136/1208)   \rReceiving objects:  95% (1148/1208)   \rReceiving objects:  96% (1160/1208)   \rReceiving objects:  97% (1172/1208)   \rReceiving objects:  98% (1184/1208)   \rReceiving objects:  99% (1196/1208)   \rReceiving objects: 100% (1208/1208)   \rReceiving objects: 100% (1208/1208), 381.07 KiB | 7.78 MiB/s, done.\n",
            "Resolving deltas:   0% (0/755)   \rResolving deltas:   1% (8/755)   \rResolving deltas:   2% (16/755)   \rResolving deltas:   3% (25/755)   \rResolving deltas:   4% (36/755)   \rResolving deltas:   5% (41/755)   \rResolving deltas:   6% (48/755)   \rResolving deltas:   7% (54/755)   \rResolving deltas:   9% (68/755)   \rResolving deltas:  10% (76/755)   \rResolving deltas:  11% (90/755)   \rResolving deltas:  12% (94/755)   \rResolving deltas:  13% (102/755)   \rResolving deltas:  14% (106/755)   \rResolving deltas:  18% (140/755)   \rResolving deltas:  21% (159/755)   \rResolving deltas:  23% (178/755)   \rResolving deltas:  26% (202/755)   \rResolving deltas:  28% (217/755)   \rResolving deltas:  29% (222/755)   \rResolving deltas:  34% (261/755)   \rResolving deltas:  35% (270/755)   \rResolving deltas:  36% (278/755)   \rResolving deltas:  37% (281/755)   \rResolving deltas:  40% (302/755)   \rResolving deltas:  43% (326/755)   \rResolving deltas:  46% (348/755)   \rResolving deltas:  47% (355/755)   \rResolving deltas:  53% (402/755)   \rResolving deltas:  54% (415/755)   \rResolving deltas:  55% (417/755)   \rResolving deltas:  58% (440/755)   \rResolving deltas:  59% (448/755)   \rResolving deltas:  60% (454/755)   \rResolving deltas:  63% (476/755)   \rResolving deltas:  66% (505/755)   \rResolving deltas:  68% (515/755)   \rResolving deltas:  69% (521/755)   \rResolving deltas:  70% (534/755)   \rResolving deltas:  72% (547/755)   \rResolving deltas:  75% (569/755)   \rResolving deltas:  76% (574/755)   \rResolving deltas:  77% (585/755)   \rResolving deltas:  78% (592/755)   \rResolving deltas:  79% (597/755)   \rResolving deltas:  80% (604/755)   \rResolving deltas:  81% (613/755)   \rResolving deltas:  82% (620/755)   \rResolving deltas:  83% (628/755)   \rResolving deltas:  84% (636/755)   \rResolving deltas:  85% (646/755)   \rResolving deltas:  87% (660/755)   \rResolving deltas:  89% (676/755)   \rResolving deltas:  91% (694/755)   \rResolving deltas:  92% (696/755)   \rResolving deltas:  93% (705/755)   \rResolving deltas:  95% (719/755)   \rResolving deltas:  96% (732/755)   \rResolving deltas:  97% (733/755)   \rResolving deltas:  98% (740/755)   \rResolving deltas:  99% (749/755)   \rResolving deltas: 100% (755/755)   \rResolving deltas: 100% (755/755), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9j49W6VMr4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -r SyferText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2tqSTudMrpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/SyferText')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tguh32pM7OZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e95619f-e33e-4204-f69f-c95a11fcfa08"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'classifier'\n",
            "  warnings.warn(msg)\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating syfertext.egg-info\n",
            "writing syfertext.egg-info/PKG-INFO\n",
            "writing dependency_links to syfertext.egg-info/dependency_links.txt\n",
            "writing requirements to syfertext.egg-info/requires.txt\n",
            "writing top-level names to syfertext.egg-info/top_level.txt\n",
            "writing manifest file 'syfertext.egg-info/SOURCES.txt'\n",
            "writing manifest file 'syfertext.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/syfertext\n",
            "copying syfertext/vectors.py -> build/lib/syfertext\n",
            "copying syfertext/utils.py -> build/lib/syfertext\n",
            "copying syfertext/language.py -> build/lib/syfertext\n",
            "copying syfertext/doc.py -> build/lib/syfertext\n",
            "copying syfertext/__init__.py -> build/lib/syfertext\n",
            "copying syfertext/token_exception.py -> build/lib/syfertext\n",
            "copying syfertext/token.py -> build/lib/syfertext\n",
            "copying syfertext/string_store.py -> build/lib/syfertext\n",
            "copying syfertext/underscore.py -> build/lib/syfertext\n",
            "copying syfertext/char_classes.py -> build/lib/syfertext\n",
            "copying syfertext/tokenizer.py -> build/lib/syfertext\n",
            "copying syfertext/stop_words.py -> build/lib/syfertext\n",
            "copying syfertext/vocab.py -> build/lib/syfertext\n",
            "copying syfertext/punctuations.py -> build/lib/syfertext\n",
            "copying syfertext/lex_attrs.py -> build/lib/syfertext\n",
            "copying syfertext/lexeme.py -> build/lib/syfertext\n",
            "copying syfertext/attrs.py -> build/lib/syfertext\n",
            "creating build/lib/syfertext/pointers\n",
            "copying syfertext/pointers/__init__.py -> build/lib/syfertext/pointers\n",
            "copying syfertext/pointers/doc_pointer.py -> build/lib/syfertext/pointers\n",
            "creating build/lib/syfertext/pipeline\n",
            "copying syfertext/pipeline/subpipeline.py -> build/lib/syfertext/pipeline\n",
            "copying syfertext/pipeline/__init__.py -> build/lib/syfertext/pipeline\n",
            "copying syfertext/pipeline/simple_tagger.py -> build/lib/syfertext/pipeline\n",
            "creating build/lib/syfertext/pipeline/pointers\n",
            "copying syfertext/pipeline/pointers/subpipeline_pointer.py -> build/lib/syfertext/pipeline/pointers\n",
            "copying syfertext/pipeline/pointers/__init__.py -> build/lib/syfertext/pipeline/pointers\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/vectors.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/utils.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "creating build/bdist.linux-x86_64/egg/syfertext/pointers\n",
            "copying build/lib/syfertext/pointers/__init__.py -> build/bdist.linux-x86_64/egg/syfertext/pointers\n",
            "copying build/lib/syfertext/pointers/doc_pointer.py -> build/bdist.linux-x86_64/egg/syfertext/pointers\n",
            "copying build/lib/syfertext/language.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/doc.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/__init__.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/token_exception.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/token.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/string_store.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/underscore.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/char_classes.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/tokenizer.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/stop_words.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/vocab.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/punctuations.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/lex_attrs.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "copying build/lib/syfertext/lexeme.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "creating build/bdist.linux-x86_64/egg/syfertext/pipeline\n",
            "creating build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers\n",
            "copying build/lib/syfertext/pipeline/pointers/subpipeline_pointer.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers\n",
            "copying build/lib/syfertext/pipeline/pointers/__init__.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers\n",
            "copying build/lib/syfertext/pipeline/subpipeline.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline\n",
            "copying build/lib/syfertext/pipeline/__init__.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline\n",
            "copying build/lib/syfertext/pipeline/simple_tagger.py -> build/bdist.linux-x86_64/egg/syfertext/pipeline\n",
            "copying build/lib/syfertext/attrs.py -> build/bdist.linux-x86_64/egg/syfertext\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/vectors.py to vectors.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pointers/doc_pointer.py to doc_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/language.py to language.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/doc.py to doc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/token_exception.py to token_exception.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/token.py to token.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/string_store.py to string_store.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/underscore.py to underscore.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/char_classes.py to char_classes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/tokenizer.py to tokenizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/stop_words.py to stop_words.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/vocab.py to vocab.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/punctuations.py to punctuations.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/lex_attrs.py to lex_attrs.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/lexeme.py to lexeme.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers/subpipeline_pointer.py to subpipeline_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/subpipeline.py to subpipeline.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/pipeline/simple_tagger.py to simple_tagger.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syfertext/attrs.py to attrs.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syfertext.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/syfertext-0.1.0.dev2-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing syfertext-0.1.0.dev2-py3.6.egg\n",
            "Copying syfertext-0.1.0.dev2-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding syfertext 0.1.0.dev2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg\n",
            "Processing dependencies for syfertext==0.1.0.dev2\n",
            "Searching for requests==2.22.0\n",
            "Reading https://pypi.org/simple/requests/\n",
            "Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl#sha256=9cf5292fcd0f598c671cfc1e0d7d1a7f13bb8085e9a590f48c010551dc6c4b31\n",
            "Best match: requests 2.22.0\n",
            "Processing requests-2.22.0-py2.py3-none-any.whl\n",
            "Installing requests-2.22.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding requests 2.22.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/requests-2.22.0-py3.6.egg\n",
            "Searching for syft==0.2.4\n",
            "Reading https://pypi.org/simple/syft/\n",
            "Downloading https://files.pythonhosted.org/packages/1f/8b/dc9a253392908d480322466832d618d85cdb1b66a1781604cf1064b50c32/syft-0.2.4-py3-none-any.whl#sha256=1a836fc9bb3344cf50ff76fffe73218c932adb1c388a72ab63f033dfcfe627e6\n",
            "Best match: syft 0.2.4\n",
            "Processing syft-0.2.4-py3-none-any.whl\n",
            "Installing syft-0.2.4-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding syft 0.2.4 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/syft-0.2.4-py3.6.egg\n",
            "Searching for mmh3==2.5.1\n",
            "Reading https://pypi.org/simple/mmh3/\n",
            "Downloading https://files.pythonhosted.org/packages/fa/7e/3ddcab0a9fcea034212c02eb411433db9330e34d626360b97333368b4052/mmh3-2.5.1.tar.gz#sha256=185209a217c52afe43e079e5b232d0ef0f3a262601eaaf4371326ab6dcbec508\n",
            "Best match: mmh3 2.5.1\n",
            "Processing mmh3-2.5.1.tar.gz\n",
            "Writing /tmp/easy_install-fh6_g9bu/mmh3-2.5.1/setup.cfg\n",
            "Running mmh3-2.5.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-fh6_g9bu/mmh3-2.5.1/egg-dist-tmp-gt_wumt3\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.mmh3.cpython-36: module references __file__\n",
            "creating /usr/local/lib/python3.6/dist-packages/mmh3-2.5.1-py3.6-linux-x86_64.egg\n",
            "Extracting mmh3-2.5.1-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding mmh3 2.5.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mmh3-2.5.1-py3.6-linux-x86_64.egg\n",
            "Searching for tqdm==4.36.1\n",
            "Reading https://pypi.org/simple/tqdm/\n",
            "Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl#sha256=dd3fcca8488bb1d416aa7469d2f277902f26260c45aa86b667b074cd44b3b115\n",
            "Best match: tqdm 4.36.1\n",
            "Processing tqdm-4.36.1-py2.py3-none-any.whl\n",
            "Installing tqdm-4.36.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding tqdm 4.36.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/tqdm-4.36.1-py3.6.egg\n",
            "Searching for websockets~=8.1.0\n",
            "Reading https://pypi.org/simple/websockets/\n",
            "Downloading https://files.pythonhosted.org/packages/cf/cb/c35513c4a0ff24ca13e33f7336ba8c1a864449fad9fea8e37abdad11c38d/websockets-8.1-cp36-cp36m-manylinux1_x86_64.whl#sha256=4f9f7d28ce1d8f1295717c2c25b732c2bc0645db3215cf757551c392177d7cb8\n",
            "Best match: websockets 8.1\n",
            "Processing websockets-8.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing websockets-8.1-cp36-cp36m-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding websockets 8.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/websockets-8.1-py3.6-linux-x86_64.egg\n",
            "Searching for websocket-client~=0.57.0\n",
            "Reading https://pypi.org/simple/websocket-client/\n",
            "Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl#sha256=0fc45c961324d79c781bab301359d5a1b00b13ad1b10415a4780229ef71a5549\n",
            "Best match: websocket-client 0.57.0\n",
            "Processing websocket_client-0.57.0-py2.py3-none-any.whl\n",
            "Installing websocket_client-0.57.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding websocket-client 0.57.0 to easy-install.pth file\n",
            "Installing wsdump.py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/websocket_client-0.57.0-py3.6.egg\n",
            "Searching for syft-proto~=0.2.5.a1\n",
            "Reading https://pypi.org/simple/syft-proto/\n",
            "Downloading https://files.pythonhosted.org/packages/c7/ab/849e6ef6c0e7af1a2a1d7a18f478fa07cd2217ed63867ab101ad5abff302/syft_proto-0.2.5a1-py3-none-any.whl#sha256=cdb0d67c1a70af83e5611e083fe63097eae207716c62aa5f3291bc2fb1aa55d2\n",
            "Best match: syft-proto 0.2.5a1\n",
            "Processing syft_proto-0.2.5a1-py3-none-any.whl\n",
            "Installing syft_proto-0.2.5a1-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding syft-proto 0.2.5a1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/syft_proto-0.2.5a1-py3.6.egg\n",
            "Searching for phe~=1.4.0\n",
            "Reading https://pypi.org/simple/phe/\n",
            "Downloading https://files.pythonhosted.org/packages/32/0e/568e97b014eb14e794a1258a341361e9da351dc6240c63b89e1541e3341c/phe-1.4.0.tar.gz#sha256=b5785c8e824eb7b02ebbe9b1e2080982d48a10db7b827a6771e04e22da99f473\n",
            "Best match: phe 1.4.0\n",
            "Processing phe-1.4.0.tar.gz\n",
            "Writing /tmp/easy_install-pgkavwe4/phe-1.4.0/setup.cfg\n",
            "Running phe-1.4.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-pgkavwe4/phe-1.4.0/egg-dist-tmp-lg2juchj\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving phe-1.4.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding phe 1.4.0 to easy-install.pth file\n",
            "Installing pheutil script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/phe-1.4.0-py3.6.egg\n",
            "Searching for lz4~=3.0.2\n",
            "Reading https://pypi.org/simple/lz4/\n",
            "Downloading https://files.pythonhosted.org/packages/e7/81/011fef8766fb0ef681037ad6fee96168ee03a864464986cbaa23e5357704/lz4-3.0.2-cp36-cp36m-manylinux2010_x86_64.whl#sha256=fc26c3902df2a8bfc0c8451bf08e265aa586fdf8f64add1d5286a12cd91e4e4a\n",
            "Best match: lz4 3.0.2\n",
            "Processing lz4-3.0.2-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "Installing lz4-3.0.2-cp36-cp36m-manylinux2010_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding lz4 3.0.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/lz4-3.0.2-py3.6-linux-x86_64.egg\n",
            "Searching for flask-socketio~=4.2.1\n",
            "Reading https://pypi.org/simple/flask-socketio/\n",
            "Downloading https://files.pythonhosted.org/packages/66/44/edc4715af85671b943c18ac8345d0207972284a0cd630126ff5251faa08b/Flask_SocketIO-4.2.1-py2.py3-none-any.whl#sha256=7ff5b2f5edde23e875a8b0abf868584e5706e11741557449bc5147df2cd78268\n",
            "Best match: Flask-SocketIO 4.2.1\n",
            "Processing Flask_SocketIO-4.2.1-py2.py3-none-any.whl\n",
            "Installing Flask_SocketIO-4.2.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding Flask-SocketIO 4.2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/Flask_SocketIO-4.2.1-py3.6.egg\n",
            "Searching for Pillow~=6.2.2\n",
            "Reading https://pypi.org/simple/Pillow/\n",
            "Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl#sha256=92b83b380f9181cacc994f4c983d95a9c8b00b50bf786c66d235716b526a3332\n",
            "Best match: Pillow 6.2.2\n",
            "Processing Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding Pillow 6.2.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/Pillow-6.2.2-py3.6-linux-x86_64.egg\n",
            "Searching for protobuf>=3.11.1\n",
            "Reading https://pypi.org/simple/protobuf/\n",
            "Downloading https://files.pythonhosted.org/packages/57/02/5432412c162989260fab61fa65e0a490c1872739eb91a659896e4d554b26/protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl#sha256=adf0e4d57b33881d0c63bb11e7f9038f98ee0c3e334c221f0858f826e8fb0151\n",
            "Best match: protobuf 3.11.3\n",
            "Processing protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding protobuf 3.11.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/protobuf-3.11.3-py3.6-linux-x86_64.egg\n",
            "Searching for python-socketio>=4.3.0\n",
            "Reading https://pypi.org/simple/python-socketio/\n",
            "Downloading https://files.pythonhosted.org/packages/10/cb/631c0b713daea3938e66d4c0923e88f3c0b57b026f860ea76e0337bc9c7a/python_socketio-4.5.1-py2.py3-none-any.whl#sha256=81280cbbb7018d8ecdd006bf6025979733d347c0f2612282c1e21f6ed7d3b55b\n",
            "Best match: python-socketio 4.5.1\n",
            "Processing python_socketio-4.5.1-py2.py3-none-any.whl\n",
            "Installing python_socketio-4.5.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding python-socketio 4.5.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/python_socketio-4.5.1-py3.6.egg\n",
            "Searching for python-engineio>=3.9.0\n",
            "Reading https://pypi.org/simple/python-engineio/\n",
            "Downloading https://files.pythonhosted.org/packages/6c/aa/c975982df73c4bcd087732db14b05306e8a3f3f24596cc18647746539290/python_engineio-3.12.1-py2.py3-none-any.whl#sha256=222926adb4bc6e03a8fc8e0ef2a3309f030c1c3f8e0fcc94c9ba214574565f02\n",
            "Best match: python-engineio 3.12.1\n",
            "Processing python_engineio-3.12.1-py2.py3-none-any.whl\n",
            "Installing python_engineio-3.12.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding python-engineio 3.12.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/python_engineio-3.12.1-py3.6.egg\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.8\n",
            "Best match: idna 2.8\n",
            "Adding idna 2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2020.4.5.1\n",
            "Best match: certifi 2020.4.5.1\n",
            "Adding certifi 2020.4.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tornado==4.5.3\n",
            "Best match: tornado 4.5.3\n",
            "Adding tornado 4.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.4.0\n",
            "Best match: torch 1.4.0\n",
            "Adding torch 1.4.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torchvision==0.5.0\n",
            "Best match: torchvision 0.5.0\n",
            "Adding torchvision 0.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tblib==1.6.0\n",
            "Best match: tblib 1.6.0\n",
            "Adding tblib 1.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.2\n",
            "Best match: numpy 1.18.2\n",
            "Adding numpy 1.18.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for msgpack==1.0.0\n",
            "Best match: msgpack 1.0.0\n",
            "Adding msgpack 1.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask==1.1.2\n",
            "Best match: Flask 1.1.2\n",
            "Adding Flask 1.1.2 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Jinja2==2.11.1\n",
            "Best match: Jinja2 2.11.1\n",
            "Adding Jinja2 2.11.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for click==7.1.1\n",
            "Best match: click 7.1.1\n",
            "Adding click 7.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==46.1.3\n",
            "Best match: setuptools 46.1.3\n",
            "Adding setuptools 46.1.3 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for MarkupSafe==1.1.1\n",
            "Best match: MarkupSafe 1.1.1\n",
            "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for syfertext==0.1.0.dev2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpQH2yapL4id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hide warnings (nothing to do with SyferText)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c9uMU_OL4io",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ac1aa010-d98c-4193-e329-33fa680ddb09"
      },
      "source": [
        "import syft as sy\n",
        "import torch\n",
        "import syfertext\n",
        "\n",
        "# Import PySyft's String class\n",
        "from syft.generic.string import String"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Torch was already hooked... skipping hooking process\n",
            "WARNING:root:Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u39hP2eLL4iy",
        "colab_type": "text"
      },
      "source": [
        "We now need to hook PyTorch using the TorchHook in PySyft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtwfGFcWL4i0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94eadc06-9242-4311-c713-7cb1100ab54f"
      },
      "source": [
        "hook = sy.TorchHook(torch)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY0Qnl2YL4i9",
        "colab_type": "text"
      },
      "source": [
        "This will endow PyTorch with magic powers, privacy-preserving deep learning powers, such as Federated Learning, Differential Privacy, Encrypted Training tools and more. To learn more about PySyft, you can check out its awesome [tutorial notebooks](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcAZk7-tL4i_",
        "colab_type": "text"
      },
      "source": [
        "Every machine in PySyft is called a worker. Since we are using SyferText to tokenize a string on a remote machine, then we should get an instance of the object representing that worker. So let's now create fours workers. We will call the local worker 'me', and the remote workers 'bob' and 'alice'. A fourth worker that will act as the crypto provider for SMPC, the encryption algorithm PySyft uses, should also be created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkh24cciL4jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The local worker\n",
        "me = hook.local_worker\n",
        "\n",
        "# The remote workers\n",
        "bob = sy.VirtualWorker(hook, id = 'bob')\n",
        "alice = sy.VirtualWorker(hook, id = 'alice')\n",
        "\n",
        "# The crypto provider\n",
        "crypto_provider = sy.VirtualWorker(hook, id = 'crypto_provider')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0hrcKXwL4jL",
        "colab_type": "text"
      },
      "source": [
        "We are now ready to load the language model. The only language model available for the moment in SyferText is `en_core_web_lg`, which is a model for English language simplified from spaCy's language model with the same name. Check out the  properties of that model [here](https://spacy.io/models/en#en_core_web_lg)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ai6ONu3L4jM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1f0d020e-8397-4e4e-cc79-ef14d8d104b0"
      },
      "source": [
        "nlp = syfertext.load('en_core_web_lg', owner = me)\n",
        "\n",
        "type(nlp), nlp.owner"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing to download language model `en_core_web_lg` ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "en_core_web_lg: 860MB [00:16, 51.0MB/s]                          \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(syfertext.language.Language, <VirtualWorker id:me #objects:0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9k7HYCvZ-Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"sbsg sdg sddgerh dfhbherh dsthth vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv sfdbndf dfher ergerg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC7pLVHDbIlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lex = nlp.vocab[\"fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX7eLZpgZ-JO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb86df22-bd0d-4241-aef3-4817ba51e22d"
      },
      "source": [
        "import sys\n",
        "sys.getsizeof(lex)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qswrI75xZ-Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOvjk3toZ-B5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzqAF7N0L4jU",
        "colab_type": "text"
      },
      "source": [
        "Notice from the cell's output that the `nlp` variable is an object of the `Language` class, and similar to all PySyft objects, it has an owner, which is a PySyft `VirtualWorker` representing our local machine. This corresponds to the illustration I showed you above were the `Language` object was shown to reside in the local worker."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKzPyhALL4jW",
        "colab_type": "text"
      },
      "source": [
        "We are now going to create a PySyft `String` and send it to `bob`. This will be our remote string that we are going to tokenize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3nwYAUDL4jX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66e94097-eda8-4783-cbd2-ab28987fa4e1"
      },
      "source": [
        "string = String('A string to tokenize')\n",
        "\n",
        "# Send the string to the remote worker `bob`\n",
        "string_ptr = string.send(bob)\n",
        "\n",
        "type(string_ptr)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "syft.generic.pointers.string_pointer.StringPointer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxJLxzL2L4jh",
        "colab_type": "text"
      },
      "source": [
        "Notice that the variable `string_ptr` is a `StringPointer` object returned by the `send()` method of the worker object. Let's make sure that the string is really sent to bob."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xzGoNl3Njec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07714c31-58b0-432b-c878-857bbc32cb70"
      },
      "source": [
        "print(string.owner)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<VirtualWorker id:me #objects:0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f94msyPQL4jj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4de3b41b-f2d5-4e7c-f6ff-95767f525a59"
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{89987704768: 'A string to tokenize'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i8GzVhRL4jr",
        "colab_type": "text"
      },
      "source": [
        "Notice that `bob`'s object store now includes the PySyft string we are willing to tokenizer.\n",
        "\n",
        "You might have noticed that printing out the `_objects` attribute has actually revealed the string text. This of course violates our assumption that the remote string is private. This is one main developement issue SyferText is going to integrate in the near future.\n",
        "\n",
        "We now have all what we need to tokenize the string. Let's do it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk_LJu8fL4js",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6308ac98-69d5-4e87-d020-124e8c13a398"
      },
      "source": [
        "doc_ptr = nlp(string_ptr)\n",
        "\n",
        "# Some checks\n",
        "print(type(doc_ptr))\n",
        "print(doc_ptr)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'syfertext.pointers.doc_pointer.DocPointer'>\n",
            "[DocPointer | me:83887027463 -> bob:71332777166]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-WQdlFBL4j0",
        "colab_type": "text"
      },
      "source": [
        "From the above output, you can see that calling `nlp` with the `StringPointer` as its argument returns a `DocPointer` object that points to a `Doc` with a specified ID residing on `bob`, the remote worker.\n",
        "\n",
        "Let's check out if `bob` really has a `Doc` object with that ID:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbxBCXmKL4j2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "11b960c8-92e4-42b2-fe13-e9877a21aac3"
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{54155574005: SubPipeline[tokenizer],\n",
              " 71332777166: Doc>None,\n",
              " 89987704768: 'A string to tokenize'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OpvA2pML4kB",
        "colab_type": "text"
      },
      "source": [
        "It does! `bob` has a `Doc` with the same ID specified by the `DocPointer` printout above. Moreover, the `Tokenizer` also resides on `bob` which is what you saw in the above illustration of SyferText's architecture at the beginning of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulW736ngL4kB",
        "colab_type": "text"
      },
      "source": [
        "Using that `DocPointer` we can now get an SMPC-encrypted string vector. For the moment, the string vector here is simply a concatenation of the individual token vectors of the string. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrmZAyAXL4kG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba8a03fb-c66b-42c5-c435-98b0f6ed57ea"
      },
      "source": [
        "doc_vector_enc = doc_ptr.get_encrypted_vector(bob, alice, crypto_provider = crypto_provider)\n",
        "\n",
        "print(f' Vector size is {doc_vector_enc.shape[0]}')\n",
        "print(doc_vector_enc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7eda4cf48fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_vector_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_ptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encrypted_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrypto_provider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrypto_provider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' Vector size is {doc_vector_enc.shape[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_vector_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg/syfertext/pointers/doc_pointer.py\u001b[0m in \u001b[0;36mget_encrypted_vector\u001b[0;34m(self, crypto_provider, requires_grad, *workers)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Send the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mdoc_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# I call get because the returned object is a PointerTensor to the AdditiveSharedTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.2.4-py3.6.egg/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, return_ids)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorCommandMessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.2.4-py3.6.egg/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.2.4-py3.6.egg/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_pending_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.2.4-py3.6.egg/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;34m\"\"\"receive message\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.2.4-py3.6.egg/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# Step 1: route message to appropriate function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_router\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.2.4-py3.6.egg/syft/workers/base.py\u001b[0m in \u001b[0;36mexecute_tensor_command\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_tensor_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorCommandMessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPointerTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComputationAction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_computation_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_communication_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft-0.2.4-py3.6.egg/syft/workers/base.py\u001b[0m in \u001b[0;36mexecute_computation_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                     \u001b[0;31m# TODO Andrew thinks this is gross, please fix. Instead need to properly deserialize strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg/syfertext/doc.py\u001b[0m in \u001b[0;36mget_encrypted_vector\u001b[0;34m(self, crypto_provider, requires_grad, excluded_tokens, *workers)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Storing the average of vectors of each in-vocabulary token's vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mdoc_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcluded_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcluded_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;31m# Create a Syft/Torch tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg/syfertext/doc.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, excluded_tokens)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# if the excluded_token dict in None all token are included\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexcluded_tokens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# enforcing that the values of the excluded_tokens dict are sets, not lists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg/syfertext/doc.py\u001b[0m in \u001b[0;36mvector\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mvector_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m# Get the vector of the token if one exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg/syfertext/doc.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# Yield a Token object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg/syfertext/doc.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Create a Token object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg/syfertext/token.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab, doc, token_meta)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# LexMeta object for the corresponding token string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_by_orth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Whether the token is followed by a single white\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg/syfertext/vocab.py\u001b[0m in \u001b[0;36mget_by_orth\u001b[0;34m(self, orth)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# Create the new LexemeMeta object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_lex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_lex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mLexemeMeta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syfertext-0.1.0.dev2-py3.6.egg/syfertext/vocab.py\u001b[0m in \u001b[0;36m_create_lex\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# Traverse all the lexical attributes getters in the dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlex_attr_getters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJPXXq4KL4kM",
        "colab_type": "text"
      },
      "source": [
        "As expected, the returned vector is an SMPC-encrypted PySyft `AdditiveSharingTensor` object. It is encrypted into two shares residing in `bob` and `alice` workers. It has a size of 1200 which corresponds to the size of 4 concatentated token vectors each of size 300.\n",
        "\n",
        "Accessing individual token attributes (within the limits of available access rights) through a `DocPointer` object is not implemented yet, but it will soon be. Please check out [this tutorial](https://bit.ly/2RQ9lwl) on local string tokenization to see how individual tokens can be accessed using a `Doc` object. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1AjjWLcL4kO",
        "colab_type": "text"
      },
      "source": [
        "### That's it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDo_6fxwL4kP",
        "colab_type": "text"
      },
      "source": [
        "You now know how to use SyferText to tokenize a remote string by manipulating a string pointer. You have seen how SyferText's distributed architecture make that easy by leveraging PySyft which, in turn, handles all the communication logic between workers.\n",
        "\n",
        "However, since SyferText is still in its developement phase, more features and methods are constantly being added and/or modified. We will make sure to update this tutorial whenever such new features are released."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1PynIBVL4kQ",
        "colab_type": "text"
      },
      "source": [
        "If you have any questions or suggestions, you can DM me on OpenMined's [slack channel](http://slack.openmined.org/), or otherwise contact me directly on my [Twitter page](https://twitter.com/alan_aboudib)."
      ]
    }
  ]
}